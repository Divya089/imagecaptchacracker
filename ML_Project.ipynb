{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb_beAX2npjR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory containing the train.csv\n",
        "dir_path = \"/kaggle/input/fiu-cap5610-spring-2023\"\n",
        "file_name = \"train.csv\"\n",
        "# Join the directory path and the file name\n",
        "path = os.path.join(dir_path, file_name)\n",
        "# Read the file using pandas. Read the train CSV file containing the CAPTCHA image IDs and their labels\n",
        "captcha_id = pd.read_csv(path)\n",
        "# Display the first few (5) rows of the dataframe\n",
        "captcha_id.head()"
      ],
      "metadata": {
        "id": "-TT0Lo7ynu4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'id' column to string type\n",
        "captcha_id['id'] = captcha_id['id'].astype('str')"
      ],
      "metadata": {
        "id": "5wDUXLMqnymN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory containing the CAPTCHA images\n",
        "dir_path = \"/kaggle/input/fiu-cap5610-spring-2023\"\n",
        "file_name = \"images\"\n",
        "# Join the directory path and the file name\n",
        "image_path = os.path.join(dir_path, file_name)"
      ],
      "metadata": {
        "id": "HQuJK-oJn1U7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store the CAPTCHA images and their labels\n",
        "captcha_data = {}\n",
        "# Import necessary libraries\n",
        "from PIL import Image\n",
        "import cv2\n",
        "# Initialize an empty list to store individual letters\n",
        "letters = []\n",
        "# Loop over each CAPTCHA image in the training set\n",
        "for c_id,c_class in captcha_id.values:\n",
        "    # Load the CAPTCHA image\n",
        "    captcha = Image.open(f\"{image_path}/{c_id}.png\")\n",
        "    # Convert the image to grayscale\n",
        "    captcha = captcha.convert('L')\n",
        "    # Convert the image to a numpy array\n",
        "    captcha = np.array(captcha)\n",
        "    # Apply Otsu's thresholding to binarize the image\n",
        "    _,cap_thresh = cv2.threshold(captcha,0,255,cv2.THRESH_OTSU)\n",
        "    # Apply morphological transformations to remove noise and separate the characters\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    \n",
        "    cap_eroded = cv2.erode(cap_thresh,kernel,iterations = 1)\n",
        "    \n",
        "    cap_dilated = cv2.dilate(cap_eroded,kernel,iterations = 1)\n",
        "    \n",
        "    cap_morphed = Image.fromarray(cap_dilated)\n",
        "    # Find the contours of the characters in the image\n",
        "    contours, _ = cv2.findContours(cap_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
        "    # Loop over the contours\n",
        "    for contour in contours:\n",
        "        # Get the bounding box of the contour\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        # Crop the letter from the CAPTCHA\n",
        "        letter_cap = cap_morphed.crop((x, y, x+w, y+h))\n",
        "        # Resize the letter to 28x28 pixels\n",
        "        letter_cap_resized = letter_cap.resize((28, 28))\n",
        "        # Convert the letter to a NumPy array\n",
        "        letter_cap_arr = np.array(letter_cap_resized)#.flatten()\n",
        "        # Store the letter and its corresponding label in the captcha_data dictionary\n",
        "        captcha_data[c_id] = {'image':letter_cap_arr,'label':c_class}\n",
        "        # Append the letter array to the letters list\n",
        "        letters.append(letter_cap_arr)\n"
      ],
      "metadata": {
        "id": "p-SVDC0Sn5mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features and labels from captcha_data\n",
        "features = [captcha_data[key]['image'] for key in captcha_data.keys()]\n",
        "labels = [captcha_data[key]['label'] for key in captcha_data.keys()]"
      ],
      "metadata": {
        "id": "bT-waWGon9q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_images,val_images,train_labels,val_labels = train_test_split(features,labels, test_size=0.25, random_state=42)\n",
        "# Reshape the image arrays\n",
        "train_images = np.array(train_images).reshape((-1, 28, 28, 1))\n",
        "val_images = np.array(val_images).reshape((-1, 28, 28, 1))\n",
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(val_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "F-X15bQZn_tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numerical values (Encode the label arrays as numerical values)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "val_labels = label_encoder.transform(val_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "J58CQsqzoCSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the convolutional neural network model architecture\n",
        "\n",
        "import tensorflow as tf\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), strides=2, padding='same', activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dropout(0.4),\n",
        "tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5), strides=2, padding='same', activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dropout(0.4),\n",
        "tf.keras.layers.Conv2D(filters=128, kernel_size=(4, 4), activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Flatten(),\n",
        "tf.keras.layers.Dropout(0.4),\n",
        "tf.keras.layers.Dense(256, activation='relu'),\n",
        "tf.keras.layers.BatchNormalization(),\n",
        "tf.keras.layers.Dropout(0.4),\n",
        "tf.keras.layers.Dense(26, activation='softmax')\n",
        "])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wKnhz72zoEpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "O6s1_3k-oezy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=30, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "AU8IcL0yohiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ooU8Y5SPokKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)"
      ],
      "metadata": {
        "id": "eS5QmzQeonbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory containing the test.csv\n",
        "dir_path = \"/kaggle/input/fiu-cap5610-spring-2023\"\n",
        "\n",
        "file_name = \"test.csv\"\n",
        "# Join the directory path and the file name\n",
        "test_path = os.path.join(dir_path, file_name)\n",
        "# Read the file using pandas. Read the test CSV file containing the CAPTCHA image IDs \n",
        "captcha_test = pd.read_csv(test_path)\n",
        "# Display the first few (5) rows of the dataframe\n",
        "captcha_test.head()"
      ],
      "metadata": {
        "id": "xyNeqXxgopPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'id' column to string type\n",
        "captcha_test['id'] = captcha_test['id'].astype('str')"
      ],
      "metadata": {
        "id": "wMR1jm2norRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory containing the CAPTCHA images\n",
        "dir_path = \"/kaggle/input/fiu-cap5610-spring-2023\"\n",
        "file_name = \"images\"\n",
        "# Join the directory path and the file name\n",
        "image_path = os.path.join(dir_path, file_name)\n"
      ],
      "metadata": {
        "id": "Z2aXOGZBotfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from PIL import Image\n",
        "import cv2\n",
        "# Initialize an empty dictionary to store the CAPTCHA images and their labels\n",
        "test_captcha_data = {}\n",
        "for c_id in captcha_test['id']:\n",
        "    # Load the CAPTCHA image\n",
        "    captcha = Image.open(f\"{image_path}/{c_id}.png\")\n",
        "    # Convert the image to grayscale\n",
        "    captcha = captcha.convert('L')\n",
        "    # Convert the image to a numpy array\n",
        "    captcha = np.array(captcha)\n",
        "    # Apply Otsu's thresholding to binarize the image\n",
        "    _,cap_thresh = cv2.threshold(captcha,0,255,cv2.THRESH_OTSU)\n",
        "    # Apply morphological transformations to remove noise and separate the characters\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "    \n",
        "    cap_eroded = cv2.erode(cap_thresh,kernel,iterations = 1)\n",
        "    \n",
        "    cap_dilated = cv2.dilate(cap_eroded,kernel,iterations = 1)\n",
        "    \n",
        "    cap_morphed = Image.fromarray(cap_dilated)\n",
        "    # Find the contours of the characters in the image\n",
        "    contours, _ = cv2.findContours(cap_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
        "    \n",
        "    letters = []\n",
        "    # Loop over the contours\n",
        "    for contour in contours:\n",
        "        # Get the bounding box of the contour\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        # Crop the letter from the CAPTCHA\n",
        "        letter_cap = cap_morphed.crop((x, y, x+w, y+h))\n",
        "        # Resize the letter to 28x28 pixels\n",
        "        letter_cap_resized = letter_cap.resize((28, 28))\n",
        "        # Convert the letter to a NumPy array\n",
        "        letter_cap_arr = np.array(letter_cap_resized)#.flatten()\n",
        "        \n",
        "        test_captcha_data[c_id] = letter_cap_arr\n",
        "    \n",
        "    test_images = np.array(list(test_captcha_data.values())).reshape((-1, 28, 28, 1))\n",
        "    \n"
      ],
      "metadata": {
        "id": "ynpktKGwovtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the Test set data\n",
        "predictions_test = model.predict(test_images)"
      ],
      "metadata": {
        "id": "mvWXCjFAoyIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the predictions to classes\n",
        "predicted_test_labels = label_encoder.inverse_transform(predictions_test.argmax(axis=1))"
      ],
      "metadata": {
        "id": "Vw3m1x4Po0Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions\n",
        "for i, c_id in enumerate(captcha_test['id']):\n",
        "    captcha_test.at[i, 'class'] = predicted_test_labels[i]"
      ],
      "metadata": {
        "id": "J2uNC2pUo2Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predicted labels to a CSV file\n",
        "captcha_test.to_csv('submission12.csv', index=False)"
      ],
      "metadata": {
        "id": "gpT4nu7bo4eM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}